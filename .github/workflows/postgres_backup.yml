name: Crawl and Backup GitHub Repos

on:
  workflow_dispatch:
  schedule:
    - cron: '0 2 * * *'

jobs:
  crawl:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:17
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: github_task
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U postgres"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r crawler/requirements.txt

      - name: Create shard databases & apply schema
        env:
          POSTGRES_USER: ${{ secrets.DB_USER }}
          POSTGRES_PASSWORD: ${{ secrets.DB_PASSWORD }}
        run: |
          createdb -h localhost -U $POSTGRES_USER ${{ secrets.DB_NAME_SHARD1 }}
          createdb -h localhost -U $POSTGRES_USER ${{ secrets.DB_NAME_SHARD2 }}
          psql -h localhost -U $POSTGRES_USER -d ${{ secrets.DB_NAME }} -f crawler/setup_postgres.sql
          psql -h localhost -U $POSTGRES_USER -d ${{ secrets.DB_NAME_SHARD1 }} -f crawler/setup_postgres.sql
          psql -h localhost -U $POSTGRES_USER -d ${{ secrets.DB_NAME_SHARD2 }} -f crawler/setup_postgres.sql

      - name: Crawl GitHub repos
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
          GH_TOKENS: ${{ secrets.GH_TOKENS }}
          DATABASE_URL: postgresql://${{ secrets.DB_USER }}:${{ secrets.DB_PASSWORD }}@localhost:5432/${{ secrets.DB_NAME }}
          DATABASE_URL_1: postgresql://${{ secrets.DB_USER }}:${{ secrets.DB_PASSWORD }}@localhost:5432/${{ secrets.DB_NAME_SHARD1 }}
          DATABASE_URL_2: postgresql://${{ secrets.DB_USER }}:${{ secrets.DB_PASSWORD }}@localhost:5432/${{ secrets.DB_NAME_SHARD2 }}
        run: |
          cd crawler
          python crawl_stars.py

  backup:
    runs-on: ubuntu-latest
    needs: crawl
    services:
      postgres:
        image: postgres:17
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: github_task
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U postgres"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Create backup folder
        run: mkdir -p backups

      - name: Dump all databases
        env:
          POSTGRES_USER: ${{ secrets.DB_USER }}
          POSTGRES_PASSWORD: ${{ secrets.DB_PASSWORD }}
        run: |
          DATE=$(date +"%Y%m%d_%H%M%S")
          dump_db() {
            local db_name=$1
            local out_file="backups/${db_name}_backup_${DATE}.sql"
            echo "Dumping $db_name â†’ $out_file"
            pg_dump -U $POSTGRES_USER -h localhost -F c -b -v -f "$out_file" "$db_name"
          }
          dump_db ${{ secrets.DB_NAME }}
          dump_db ${{ secrets.DB_NAME_SHARD1 }}
          dump_db ${{ secrets.DB_NAME_SHARD2 }}

      - name: Commit and Push Backup
        run: |
          git config --local user.name "github-actions"
          git config --local user.email "actions@github.com"
          git add backups/
          git commit -m "DB Backup (main + shards) - $(date +"%Y-%m-%d %H:%M:%S")" || echo "No changes to commit"
          git push
